{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzPYgNicMf0M",
        "outputId": "fc0b78bc-9292-4620-d5b1-99b829c65070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, numpy, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.6 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ4NNGe6TC80",
        "outputId": "c8b89ca0-5a6a-44d6-b6ba-2010aa1769cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Pose Data Pickle Creation (7 Features: XYZ+Vis + Vxyz) ---\n",
            "Video Source Directory: 'val'\n",
            "Frames to Sample per Video: 50\n",
            "Output Pickle Path: 'preprocessed_data/val_ur_fall_50_frames_7_features.pkl'\n",
            "MediaPipe Config: {'model_complexity': 1, 'min_detection_confidence': 0.5, 'min_tracking_confidence': 0.5}\n",
            "------------------------------------------------------------\n",
            "Found 12 potential video files.\n",
            "Initializing MediaPipe Pose Estimator...\n",
            "MediaPipe Pose initialized with complexity=1, min_detect_conf=0.5, min_track_conf=0.5\n",
            "Starting pre-processing for 12 videos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Videos:   8%|▊         | 1/12 [00:01<00:21,  2.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Velocity Calculation Note: Using FPS (30.00) for delta_t.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Videos: 100%|██████████| 12/12 [00:24<00:00,  2.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MediaPipe Pose resources released.\n",
            "\n",
            "Pre-processing complete. Successfully processed and generated data for 12 videos.\n",
            "Saving processed data (7 features: x,y,z,vis + vx,vy,vz) to preprocessed_data/val_ur_fall_50_frames_7_features.pkl...\n",
            "Data saved successfully.\n",
            "------------------------------------------------------------\n",
            "--- Pickle file created successfully at 'preprocessed_data/val_ur_fall_50_frames_7_features.pkl' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Prototyped with the help of Gemini\n",
        "#import cv2\n",
        "import tensorflow_hub as hub # the magic line that fixes all binary issues ;)\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import traceback\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "class MediaPipePoseEstimator:\n",
        "    def __init__(self, model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5):\n",
        "        try:\n",
        "            self.pose = mp_pose.Pose(\n",
        "                static_image_mode=False,\n",
        "                model_complexity=model_complexity,\n",
        "                enable_segmentation=False,\n",
        "                min_detection_confidence=min_detection_confidence,\n",
        "                min_tracking_confidence=min_tracking_confidence)\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing MediaPipe Pose: {e}\")\n",
        "            raise\n",
        "\n",
        "    def estimate_pose_4_features(self, image):\n",
        "        try:\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image_rgb.flags.writeable = False\n",
        "            results = self.pose.process(image_rgb)\n",
        "\n",
        "            if results.pose_landmarks:\n",
        "                landmarks = results.pose_landmarks.landmark\n",
        "                keypoints_4_np = np.array(\n",
        "                    [[lm.x, lm.y, lm.z, lm.visibility] for lm in landmarks],\n",
        "                    dtype=np.float32\n",
        "                )\n",
        "                if keypoints_4_np.shape == (33, 4):\n",
        "                    return keypoints_4_np\n",
        "                else:\n",
        "                    print(f\"Warning: MediaPipe returned unexpected landmark shape: {keypoints_4_np.shape}. Expected (33, 4).\")\n",
        "                    return None\n",
        "            else:\n",
        "                return None \n",
        "        except Exception as e:\n",
        "            print(f\"Error during MediaPipe pose estimation: {e}\")\n",
        "            return None\n",
        "\n",
        "    def close(self):\n",
        "        if hasattr(self, 'pose'):\n",
        "            self.pose.close()\n",
        "            print(\"MediaPipe Pose resources released.\")\n",
        "\n",
        "\n",
        "def derive_label_from_filename(video_path):\n",
        "    filename = os.path.basename(video_path)\n",
        "    parts = filename.lower().replace('_', '-').split('-')\n",
        "    if len(parts) >= 1:\n",
        "        label_str = parts[0]\n",
        "        if label_str == \"fall\": return 1\n",
        "        elif label_str == \"adl\": return 0\n",
        "        else:\n",
        "            print(f\"Warning: Unknown label prefix '{parts[0]}' in filename: {filename}. Defaulting to 0 (ADL). Consider adding specific handling if needed.\")\n",
        "            return 0\n",
        "    else:\n",
        "        raise ValueError(f\"Filename '{filename}' format error. Cannot derive label.\")\n",
        "\n",
        "\n",
        "# --- MODIFIED sample_frames to also return FPS ---\n",
        "def sample_frames(video_path, num_frames_to_sample):\n",
        "    frames = []\n",
        "    fps = 0.0\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        return [], fps\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    if total_frames <= 0:\n",
        "        print(f\"Warning: Video {video_path} reported 0 frames.\")\n",
        "        cap.release()\n",
        "        return [], fps\n",
        "    if total_frames <= num_frames_to_sample:\n",
        "        frame_indices = np.arange(total_frames)\n",
        "    else:\n",
        "        frame_indices = np.linspace(0, total_frames - 1, num_frames_to_sample, dtype=int)\n",
        "\n",
        "    read_success_count = 0\n",
        "    for idx in frame_indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frames.append(frame)\n",
        "            read_success_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if read_success_count == 0 and total_frames > 0:\n",
        "         print(f\"Error: Failed to read ANY frames from {video_path} despite it reporting {total_frames} total frames.\")\n",
        "         return [], fps\n",
        "\n",
        "    if len(frames) != len(frame_indices):\n",
        "         print(f\"Warning: Read {len(frames)} frames, expected {len(frame_indices)} based on sampling from {video_path}\")\n",
        "\n",
        "    return frames, fps\n",
        "\n",
        "def create_pose_data_pickle_7_features(video_dir, output_pickle_file, num_frames=500, pose_estimator_config=None):\n",
        "    \"\"\"\n",
        "\n",
        "    Pickle Structure per video:\n",
        "    {\n",
        "        'video_path': str,\n",
        "        'label': int,\n",
        "        'frames_data': [\n",
        "            {'keypoints': np.array(33, 4), 'velocities': np.array(33, 3)}, # Frame 0\n",
        "            {'keypoints': np.array(33, 4), 'velocities': np.array(33, 3)}, # Frame 1\n",
        "            ...\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(video_dir):\n",
        "        return False\n",
        "\n",
        "    # Find video files\n",
        "    video_paths = sorted(glob.glob(os.path.join(video_dir, '*.mp4'))) + \\\n",
        "                  sorted(glob.glob(os.path.join(video_dir, '*.avi'))) + \\\n",
        "                  sorted(glob.glob(os.path.join(video_dir, '*.mov')))\n",
        "    if not video_paths:\n",
        "        return False\n",
        "    print(f\"Found {len(video_paths)} potential video files.\")\n",
        "\n",
        "    if pose_estimator_config is None:\n",
        "        pose_estimator_config = {'model_complexity': 1} \n",
        "\n",
        "    pose_estimator = MediaPipePoseEstimator(**pose_estimator_config)\n",
        "    all_processed_data = []\n",
        "    skipped_videos = 0\n",
        "    videos_with_no_pose = 0\n",
        "\n",
        "    print(f\"Starting pre-processing for {len(video_paths)} videos...\")\n",
        "    for video_path in tqdm(video_paths, desc=\"Processing Videos\"):\n",
        "        try:\n",
        "            label = derive_label_from_filename(video_path)\n",
        "        except ValueError as e:\n",
        "            print(f\"Skipping video {os.path.basename(video_path)}: {e}\")\n",
        "            skipped_videos += 1\n",
        "            continue\n",
        "\n",
        "        sampled_frames, fps = sample_frames(video_path, num_frames)\n",
        "        if not sampled_frames:\n",
        "            print(f\"Skipping video {os.path.basename(video_path)}: No frames could be sampled.\")\n",
        "            skipped_videos += 1\n",
        "            continue\n",
        "\n",
        "        if fps > 0:\n",
        "            delta_t = 1.0 / fps\n",
        "            using_fps_for_velocity = True\n",
        "        else:\n",
        "            delta_t = 1.0\n",
        "            using_fps_for_velocity = False\n",
        "\n",
        "        video_frames_data_list = []\n",
        "        prev_keypoints_4_np = None\n",
        "\n",
        "        for frame in sampled_frames:\n",
        "            current_keypoints_4_np = pose_estimator.estimate_pose_4_features(frame)\n",
        "\n",
        "            if isinstance(current_keypoints_4_np, np.ndarray) and current_keypoints_4_np.shape == (33, 4):\n",
        "                if prev_keypoints_4_np is not None:\n",
        "                    delta_coords = current_keypoints_4_np[:, :3] - prev_keypoints_4_np[:, :3]\n",
        "                    velocities_np = delta_coords / delta_t\n",
        "                else:\n",
        "                    velocities_np = np.zeros((33, 3), dtype=np.float32)\n",
        "                frame_dict = {\n",
        "                    'keypoints': current_keypoints_4_np,\n",
        "                    'velocities': velocities_np\n",
        "                }\n",
        "                video_frames_data_list.append(frame_dict)\n",
        "\n",
        "                prev_keypoints_4_np = current_keypoints_4_np\n",
        "\n",
        "        if video_frames_data_list:\n",
        "            all_processed_data.append({\n",
        "                'video_path': video_path,\n",
        "                'label': label,\n",
        "                'frames_data': video_frames_data_list\n",
        "            })\n",
        "\n",
        "            if len(all_processed_data) == 1:\n",
        "                print(f\"Velocity Calculation Note: Using {'FPS ({:.2f})'.format(fps) if using_fps_for_velocity else 'Frame Index Difference'} for delta_t.\")\n",
        "        else:\n",
        "\n",
        "            videos_with_no_pose += 1\n",
        "            skipped_videos += 1 \n",
        "\n",
        "    pose_estimator.close()\n",
        "\n",
        "    print(f\"\\nPre-processing complete\")\n",
        "    try:\n",
        "        output_dir = os.path.dirname(output_pickle_file)\n",
        "        if output_dir and not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "            print(f\"Created output directory: {output_dir}\")\n",
        "\n",
        "        with open(output_pickle_file, 'wb') as f:\n",
        "            pickle.dump(all_processed_data, f)\n",
        "        print(\"Data saved successfully.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving data to pickle file: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    VIDEO_SOURCE_DIR = 'val' \n",
        "    NUM_FRAMES_TO_SAMPLE = 50     \n",
        "    OUTPUT_PICKLE_NAME = f'{os.path.basename(VIDEO_SOURCE_DIR)}_ur_fall_{NUM_FRAMES_TO_SAMPLE}_frames_7_features.pkl' \n",
        "    OUTPUT_DIR = 'preprocessed_data'\n",
        "    OUTPUT_PICKLE_PATH = os.path.join(OUTPUT_DIR, OUTPUT_PICKLE_NAME)\n",
        "\n",
        "    MP_CONFIG = {\n",
        "        'model_complexity': 1,          \n",
        "        'min_detection_confidence': 0.5,\n",
        "        'min_tracking_confidence': 0.5\n",
        "    }\n",
        "\n",
        "    print(\"--- Starting Pose Data Pickle Creation (7 Features: XYZ+Vis + Vxyz) ---\")\n",
        "    print(f\"Video Source Directory: '{VIDEO_SOURCE_DIR}'\")\n",
        "    print(f\"Frames to Sample per Video: {NUM_FRAMES_TO_SAMPLE}\")\n",
        "    print(f\"Output Pickle Path: '{OUTPUT_PICKLE_PATH}'\")\n",
        "    print(f\"MediaPipe Config: {MP_CONFIG}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "    success = create_pose_data_pickle_7_features(\n",
        "        video_dir=VIDEO_SOURCE_DIR,\n",
        "        output_pickle_file=OUTPUT_PICKLE_PATH,\n",
        "        num_frames=NUM_FRAMES_TO_SAMPLE,\n",
        "        pose_estimator_config=MP_CONFIG\n",
        "    )\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    if success:\n",
        "        print(f\"--- Pickle file created successfully at '{OUTPUT_PICKLE_PATH}' ---\")\n",
        "    else:\n",
        "        print(\"--- Pickle file creation failed ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM8Qv37uTBJV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
